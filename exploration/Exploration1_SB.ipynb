{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exploration1-SB.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 프로젝트 (1) 손글씨 분류하기"
      ],
      "metadata": {
        "id": "zSlFFYtMbpgd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "아까 노드에서 0과 3으로 분류했던 손글씨 이미지를 0~9까지 분류해 보도록 합시다.\n",
        "## (1) 필요한 모듈 import"
      ],
      "metadata": {
        "id": "u-D4mScbb9Nd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LboGklTdESj7"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "알파벳 데이터를 불러오기 위한 load_digits, 알파벳 데이터를 트레이닝, 테스트 데이터셋으로 나누기 위한 train_test_split, 모델 평가를 위한 classification_report를 불러와 줍니다.  \n",
        "추가적으로, 불러온 데이터를 여러 학습 모델에 적용시켜 비교해 볼 것이기 때문에 노드에서 배운 5가지 학습 모델을 불러왔습니다.  \n",
        "  \n",
        "\n",
        "## (2) 데이터 준비"
      ],
      "metadata": {
        "id": "gQIczSgccLho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "digits = load_digits()"
      ],
      "metadata": {
        "id": "NlDlQaY-dsfV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dir(digits))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tggvjzrEd1g-",
        "outputId": "3e00a8c1-3894-4384-c954-ac59795ba5f7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['DESCR', 'data', 'feature_names', 'frame', 'images', 'target', 'target_names']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "정상적으로 digits 데이터를 불러왔습니다. 이제 불러온 데이터를 살펴보겠습니다."
      ],
      "metadata": {
        "id": "ymn8vSeneRrg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (3) 데이터 이해하기"
      ],
      "metadata": {
        "id": "2M9GvPBCeaEd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "아까 digits 데이터가 잘 읽어졌는지 확인할 때 dir로 데이터 안에 DESCR, data, feature_names, frame, images, target, target_names 총 7개의 정보가 담겨있는 것을 확인하였습니다.  \n",
        "일단 DESCR에 있는 데이터 정보를 확인해 보겠습니다."
      ],
      "metadata": {
        "id": "MWvYaqOnenJO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(digits.DESCR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEQpQERMebyo",
        "outputId": "de9b4d70-a839-45f4-c914-26ff9303dcf6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. _digits_dataset:\n",
            "\n",
            "Optical recognition of handwritten digits dataset\n",
            "--------------------------------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 1797\n",
            "    :Number of Attributes: 64\n",
            "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
            "    :Missing Attribute Values: None\n",
            "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
            "    :Date: July; 1998\n",
            "\n",
            "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
            "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
            "\n",
            "The data set contains images of hand-written digits: 10 classes where\n",
            "each class refers to a digit.\n",
            "\n",
            "Preprocessing programs made available by NIST were used to extract\n",
            "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
            "total of 43 people, 30 contributed to the training set and different 13\n",
            "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
            "4x4 and the number of on pixels are counted in each block. This generates\n",
            "an input matrix of 8x8 where each element is an integer in the range\n",
            "0..16. This reduces dimensionality and gives invariance to small\n",
            "distortions.\n",
            "\n",
            "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
            "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
            "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
            "1994.\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
            "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
            "    Graduate Studies in Science and Engineering, Bogazici University.\n",
            "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
            "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
            "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
            "    Electrical and Electronic Engineering Nanyang Technological University.\n",
            "    2005.\n",
            "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
            "    Algorithm. NIPS. 2000.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "digits.data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gs6MpmnqeXIf",
        "outputId": "ed9f8142-248f-4bf9-c0a3-acbaa06e89d0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
              "       [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
              "       [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
              "       ...,\n",
              "       [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
              "       [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
              "       [ 0.,  0., 10., ..., 12.,  1.,  0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "digits.data로 데이터를 확인해보니 수많은 배열이 나오네요.  \n",
        "해당 데이터의 shape 속성으로 배열의 모양을 확인해 봅시다."
      ],
      "metadata": {
        "id": "X9jD7q6Wf1_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "digits.data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkkGoIqYgbKR",
        "outputId": "61117bb7-df74-4381-ff75-c626a2293b5c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1797, 64)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "64개의 숫자로 이루어진 1797개의 데이터라는 것을 확인할 수 있습니다.  \n",
        "64개의 숫자 배열은 8x8 크기의 손글씨 이미지를 1차원 배열로 표현해 둔 것이라고 합니다.  \n",
        "Image를 확인해 보고 싶은데 어떻게 해야 할까요.. matplotlib를 이용하면 이미지를 표현할 수 있다고 하네요.  \n",
        "아까 import하지 않았던 모듈이라 참조 후에 image를 표현해 보도록 하겠습니다."
      ],
      "metadata": {
        "id": "LrKIP68hgepV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.imshow(digits.data[0].reshape(8, 8), cmap='gray') # 1차원 배열을 8x8로 다시 표현하여 컬러맵 gray를 사용해 표시\n",
        "plt.axis('off') # 축 표시x\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "nqLn5qgEhNyW",
        "outputId": "db3344ae-890e-4385-ca7e-a1db2c4bc6e3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAADyUlEQVR4nO3dUVFjaRRG0T9TYyAWggSwkkgACSABL5FAJBALSCAS7higeZo6vZte6zF5+KiEXbeKB85u27YF9Pzzu38A4GvihChxQpQ4IUqcEPXvd2/udrsf+afc4/E4uvf6+jq2dblcxrZeXl7Gtm6329jWtG3bdl+97skJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEqG/PMfxUk+cR1lrrcDiMbe33+7Gtz8/Psa3T6TS2tdZa5/N5dO8rnpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IypxjuL+/H9uaPI+w1lp3d3djWx8fH2Nbb29vY1uTvx9rOccAfEOcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiMrcStnv92Nb1+t1bGut2fslk6Y/x7+NJydEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROi/spzDJfLZWzrJ5v8zm6329hWhScnRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTojLnGCb/3f79/f3Y1rTJEwmTn+P5fB7bqvDkhChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQtRu27Zfv7nb/frN/9nhcJiaWu/v72Nba6319PQ0tnU8Hse2Jr+zh4eHsa1p27btvnrdkxOixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oSozK2USY+Pj6N7z8/PY1vX63Vs63Q6jW39ZG6lwB9GnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBD17TkG4Pfx5IQocUKUOCFKnBAlTogSJ0T9ByioUst9Wxj9AAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "첫번째 데이터는 숫자 0을 표시한 것이었네요. 이번에는 다양한 Feature는 없고 이 64개의 숫자 배열을 학습시켜 원하는 답을 얻어낼 수 있는지 확인해 보겠습니다. 그러기 위해서는 일단 데이터를 분류해줘야 합니다.  \n",
        "학습시킬 데이터는 digits.data인 것 같고.. 정답은 어디에 있을까요?"
      ],
      "metadata": {
        "id": "bmVFsH6QhoVV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(digits.target))\n",
        "digits.target"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSdee8l0jWcp",
        "outputId": "5633e517-a883-4edd-e35f-a1fea5c31536"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1797\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, ..., 8, 9, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "음.. 뭔가 0 ~ 9 의 숫자로 표현된 것 같긴한데 중간이 생략되어 보여서 확실하지가 않네요.  \n",
        "하지만 target_names를 확인하면 target이 어떻게 구성되어 있는지 알 수 있습니다."
      ],
      "metadata": {
        "id": "wcb5Do2t0V9_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "digits.target_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e8rNLh80Lze",
        "outputId": "247b2e44-bdcc-48c4-d3b7-316421cea353"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "digits.target의 데이터가 정답을 담고 있는 것 같네요. 해당 데이터들을 변수에 담아둡시다."
      ],
      "metadata": {
        "id": "tr_OAO_ojqVp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "digit_data = digits.data\n",
        "digit_label = digits.target"
      ],
      "metadata": {
        "id": "7Fa48sVuj3MC"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 학습할 데이터와 정답지가 준비되었습니다. 다음으로 넘어가 보겠습니다."
      ],
      "metadata": {
        "id": "_P5D3hCd1Qay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (4) train, test 데이터 분리  \n",
        "모델 학습을 통해 훈련을 하게되면 우리는 테스트 데이터를 통해 해당 학습이 얼마나 잘 되었는가를 평가할 수 있다. 하지만 우리에게 준비된 데이터셋은 하나뿐이다.   \n",
        "훈련에 사용했던 데이터를 테스트에 사용하게 되면 마치 이미 풀어본 문제를 다시 풀라고 시키는 (당연히 맞추겠지) 행위가 되기 때문에 우리는 훈련용 데이터를 분리해서 학습이 잘 되었는지 평가를 할 것이다. 그리고 그것을 분리하는 것은 앞에서 참조한 sklearn.model_selection의 train_test_split 함수를 통해 아주 쉽게 할 수 있다."
      ],
      "metadata": {
        "id": "47HAyDHv1XJq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(digit_data,\n",
        "                                                    digit_label, \n",
        "                                                    test_size=0.2, \n",
        "                                                    random_state=22)"
      ],
      "metadata": {
        "id": "yFu_GH703B7W"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "X_train, X_test에는 각각 학습할 데이터와 답을 맞추는데 사용할 테스트 데이터가 들어가게 되고 y_train, y_test에는 학습에 사용될 정답과 테스트 데이터의 정답여부를 판단할 target data가 들어가게 된다.  \n",
        "test_size를 지정하면 해당 크기만큼 test 데이터로 가져가고 나머지는 훈련용 데이터에 들어가게 된다."
      ],
      "metadata": {
        "id": "QIDSJx4c3oYy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (5) 다양한 모델로 학습시켜보기  \n",
        "이제 훈련 데이터와 테스트 데이터가 모두 준비되었으니 학습을 시켜보자. 앞에서 언급했듯이, 5가지 모델을 전부 실행해보고 성능을 비교해 볼것이다.  \n",
        "각 모델의 사용법은 간단하다. sklearn에서 참조한 각 모델의 Classifier를 이용해 데이터를 세팅해주고 학습시킨 후 테스트 데이터로 평가를 진행한다."
      ],
      "metadata": {
        "id": "DOk2MX263_MY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decision Tree  \n",
        "Decision Tree는 데이터를 분석하여 각 특징들을 이진분류하여 스무고개처럼 각 특징들에 대해 분류된 질문을 따라 내려가서 답을 찾는 모델입니다.  \n",
        "특징이 여러개일 수록 뻗어나가는 질문들이 가지와 같다고 하여 의사결정나무 라고 합니다."
      ],
      "metadata": {
        "id": "Jt7dj9RQ4aqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decision_tree = DecisionTreeClassifier(random_state=20)\n",
        "decision_tree.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnjaDZbj4ZD2",
        "outputId": "a7d51b1c-8c3b-4324-9ca3-1a1f74fe7ce0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(random_state=20)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습이 끝났습니다. 정말 간단하네요.  \n",
        "아까 train 데이터와 test 데이터를 구분할 때도 사용했던 random_state가 신경쓰이네요.  \n",
        "컴퓨터가 랜덤한 값을 생성할 때 나름의 규칙을 통해 생성하기 때문에 완전히 랜덤한 값을 생성하는 것이 아닙니다. random_state를 지정해주게 되면 랜덤으로 나오게 되는 값이 항상 같은 규칙으로 동작하여 같은 값을 리턴한다고 합니다.  \n",
        "그럼 학습된 모델이 얼마나 정답을 잘 맞추나 봅시다.\n"
      ],
      "metadata": {
        "id": "Wxyv-JJk7NPc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = decision_tree.predict(X_test)"
      ],
      "metadata": {
        "id": "iQy2BNgo8g5B"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "y_pred에는 테스트 데이터를 기반으로 학습된 모델에서 정답을 예측하게 됩니다.  \n",
        "학습을 평가하는 데는 sklearn.metrics의 classification_report 함수를 사용합니다."
      ],
      "metadata": {
        "id": "iroRevWa8tJZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNWQIN1w868J",
        "outputId": "859f013d-7260-4fbb-c7ba-2ca059eebc14"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        32\n",
            "           1       0.75      0.82      0.79        40\n",
            "           2       0.87      0.82      0.84        33\n",
            "           3       0.83      0.87      0.85        39\n",
            "           4       0.83      0.80      0.81        44\n",
            "           5       0.88      0.83      0.86        36\n",
            "           6       0.84      0.87      0.86        31\n",
            "           7       0.84      0.87      0.85        30\n",
            "           8       0.89      0.82      0.86        40\n",
            "           9       0.83      0.86      0.85        35\n",
            "\n",
            "    accuracy                           0.85       360\n",
            "   macro avg       0.86      0.86      0.86       360\n",
            "weighted avg       0.85      0.85      0.85       360\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "오.. 뭔가 많은 결과값이 나왔네요.  \n",
        "하지만 아직 우리는 4개의 모델을 더 학습시켜봐야 합니다.  \n",
        "모델별로 y_pred를 구분하여 모델 평가지표에 대해 알아보고 나중에 비교해 보도록 합시다."
      ],
      "metadata": {
        "id": "JwekXMa69GrU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_decision_tree = decision_tree.predict(X_test)"
      ],
      "metadata": {
        "id": "7oRTZ1q79cqr"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest  \n",
        "랜덤포레스트는 의사결정트리의 단점을 보완한 학습모델입니다. 의사결정트리는 각 특징에 대해 이진분류를 하기 때문에 결정경계가 수직이어서 특정 데이터에만 잘 동작할 가능성이 높습니다.  \n",
        "랜덤포레스트는 의사결정트리를 여러개 사용해서 그 단점을 보완했습니다. 근데 이름에 랜덤이 들어가네요? 왜 랜덤이냐면 의사결정트리를 여러개 사용할 때 이진분류할 특징을 랜덤으로 골라서 사용하기 때문입니다.  \n",
        "이런식으로, 어떤 모델의 단점을 보완하기 위해 여러 모델을 합쳐서 사용하는 것을 앙상블(Ensemble)이라고 합니다.  \n",
        "랜덤포레스트 모델을 적용해 학습을 시키고 예측값을 y_pred_random_forest에 저장하겠습니다."
      ],
      "metadata": {
        "id": "8PBTqnzB98my"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_forest = RandomForestClassifier(random_state=20)\n",
        "random_forest.fit(X_train, y_train)\n",
        "y_pred_random_porest = random_forest.predict(X_test)"
      ],
      "metadata": {
        "id": "GIvkpY4c_rKk"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Support Vector Machine(SVM)  \n",
        "SVM은 Support Vector와 Hyperplane(초평면)을 이용해서 분류를 수행하는 선형 분류 알고리즘입니다.  \n",
        "흠.. 근데 우리는 0-9를 구분해야 하는데 선형 분류 알고리즘은 데이터를 두가지로 밖에 분류할 수 없지 않나.. 하겠지만 SVM은 다중 클래스 분류를 할 때 각 클래스를 다른 모든 클래스와 분류하도록 분류 모델을 여러개 만들게 됩니다. 0-9니까 분류모델이 10개 만들어지겠네요. 그리고 예측시에 모든 모델이 작동하여 가장 높은 점수를 내는 모델의 클래스를 예측 값으로 선택한다고 합니다.  \n",
        "일단 써봅시다."
      ],
      "metadata": {
        "id": "qdol4k85_8HH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svm_model = svm.SVC(random_state=20)\n",
        "svm_model.fit(X_train, y_train)\n",
        "y_pred_svm = svm_model.predict(X_test)"
      ],
      "metadata": {
        "id": "RfI75UCFBH-S"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stochastic Gradient Descent Classifier (SGDClassifier)  \n",
        "SGD는 확률적 경사하강법으로 데이터 세트에서 무작위로 균일하게 선택한 하나의 데이터 포인트를 이용하여 각 단계의 예측 경사를 계산하는 모델입니다. 솔직히 완벽하게 이해하지 못해서 더 자세히 공부해보고 회고에서 다루도록 하겠습니다.  \n",
        "결과를 뽑아봅시다.\n"
      ],
      "metadata": {
        "id": "2UlmfcFyB4J4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sgd_model = SGDClassifier(random_state=20)\n",
        "sgd_model.fit(X_train, y_train)\n",
        "y_pred_sgd = sgd_model.predict(X_test)"
      ],
      "metadata": {
        "id": "PZdi9gpBEndi"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression  \n",
        "Logistic Regression 모델은 가장 널리 알려진 선형 분류 알고리즘입니다. 소프트맥스 함수를 사용한 다중 클래스 분류 알고리즘으로 클래스 분류를 위한 로지스틱 회귀를 소프트맥스 회귀라고도 표현하지만, 분류를 수행합니다.  \n",
        "소프트맥스 함수는 분류될 클래스가 N개일 때, N차원의 벡터로 각 클래스가 정답일 확률을 표현하도록 정규화하는 함수입니다.  \n",
        "해당 데이터에선 64개의 벡터를 입력받고 10개의 벡터에 각 클래스가 될 확률을 표현할 수 있도록 데이터 학습을 통해 가중치와 편향을 조정하는 과정을 1797회 거친다 라고 생각할 수 있겠네요. 가중치와 편향을 조정할 때는 예측값 벡터와 실제값 벡터를 비교하여 오차를 줄이는 방식으로 조정합니다.  \n",
        "이것도 학습을 진행해 줍시다."
      ],
      "metadata": {
        "id": "VgYNnYt1EnHR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logistic_model = LogisticRegression(random_state=20, max_iter=5000)\n",
        "logistic_model.fit(X_train, y_train)\n",
        "y_pred_logistic = logistic_model.predict(X_test)"
      ],
      "metadata": {
        "id": "I7qK2BgbGwa_"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "logistic model을 학습하면서 오류가 발생했는데 무한 루프방지를 위한 max_iter 값이 기본으로 100으로 설정되어 있어서 반복횟수가 제한되어 발생하는 오류였다. max_iter를 조금씩 늘리다가 5000으로 설정하니 오류가 발생하지 않았다."
      ],
      "metadata": {
        "id": "nuweHg7zIXz0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (6) 모델을 평가해 보기  \n",
        "5가지의 모델으로 모두 학습을 마치고 평가를위해 예측값을 각 변수에 담아두었습니다. 이제 모델이 잘 학습된건지 평가를 해봅시다."
      ],
      "metadata": {
        "id": "MgErj1CVIq_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Decision Tree : \\n', classification_report(y_test, y_pred_decision_tree))\n",
        "print('Random Forest : \\n', classification_report(y_test, y_pred_random_porest))\n",
        "print('SVM : \\n', classification_report(y_test, y_pred_svm))\n",
        "print('SGD : \\n', classification_report(y_test, y_pred_sgd))\n",
        "print('Logistic : \\n', classification_report(y_test, y_pred_logistic))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPw9bBkiKwzJ",
        "outputId": "9cdf1f03-49a9-4843-d31f-ed200b9f7a8a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        32\n",
            "           1       0.75      0.82      0.79        40\n",
            "           2       0.87      0.82      0.84        33\n",
            "           3       0.83      0.87      0.85        39\n",
            "           4       0.83      0.80      0.81        44\n",
            "           5       0.88      0.83      0.86        36\n",
            "           6       0.84      0.87      0.86        31\n",
            "           7       0.84      0.87      0.85        30\n",
            "           8       0.89      0.82      0.86        40\n",
            "           9       0.83      0.86      0.85        35\n",
            "\n",
            "    accuracy                           0.85       360\n",
            "   macro avg       0.86      0.86      0.86       360\n",
            "weighted avg       0.85      0.85      0.85       360\n",
            "\n",
            "Random Forest : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        32\n",
            "           1       0.95      1.00      0.98        40\n",
            "           2       1.00      1.00      1.00        33\n",
            "           3       0.97      1.00      0.99        39\n",
            "           4       1.00      1.00      1.00        44\n",
            "           5       1.00      1.00      1.00        36\n",
            "           6       1.00      0.97      0.98        31\n",
            "           7       1.00      1.00      1.00        30\n",
            "           8       1.00      1.00      1.00        40\n",
            "           9       1.00      0.94      0.97        35\n",
            "\n",
            "    accuracy                           0.99       360\n",
            "   macro avg       0.99      0.99      0.99       360\n",
            "weighted avg       0.99      0.99      0.99       360\n",
            "\n",
            "SVM : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        32\n",
            "           1       0.98      1.00      0.99        40\n",
            "           2       1.00      1.00      1.00        33\n",
            "           3       1.00      0.97      0.99        39\n",
            "           4       1.00      1.00      1.00        44\n",
            "           5       1.00      1.00      1.00        36\n",
            "           6       1.00      1.00      1.00        31\n",
            "           7       0.97      1.00      0.98        30\n",
            "           8       1.00      0.97      0.99        40\n",
            "           9       1.00      1.00      1.00        35\n",
            "\n",
            "    accuracy                           0.99       360\n",
            "   macro avg       0.99      0.99      0.99       360\n",
            "weighted avg       0.99      0.99      0.99       360\n",
            "\n",
            "SGD : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        32\n",
            "           1       0.86      0.90      0.88        40\n",
            "           2       1.00      0.97      0.98        33\n",
            "           3       0.97      0.87      0.92        39\n",
            "           4       0.98      0.98      0.98        44\n",
            "           5       1.00      1.00      1.00        36\n",
            "           6       0.97      0.94      0.95        31\n",
            "           7       0.94      0.97      0.95        30\n",
            "           8       0.77      0.93      0.84        40\n",
            "           9       0.97      0.83      0.89        35\n",
            "\n",
            "    accuracy                           0.94       360\n",
            "   macro avg       0.94      0.94      0.94       360\n",
            "weighted avg       0.94      0.94      0.94       360\n",
            "\n",
            "Logistic : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        32\n",
            "           1       0.85      1.00      0.92        40\n",
            "           2       0.94      1.00      0.97        33\n",
            "           3       1.00      0.95      0.97        39\n",
            "           4       0.98      0.98      0.98        44\n",
            "           5       1.00      0.97      0.99        36\n",
            "           6       0.97      0.94      0.95        31\n",
            "           7       1.00      0.97      0.98        30\n",
            "           8       1.00      0.88      0.93        40\n",
            "           9       0.94      0.97      0.96        35\n",
            "\n",
            "    accuracy                           0.96       360\n",
            "   macro avg       0.97      0.96      0.97       360\n",
            "weighted avg       0.97      0.96      0.96       360\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "각 모델별 학습에 대한 예측 수치가 나타났습니다.  \n",
        "Precision, Recall, F1 score는 오차행렬에서 표현되는 TP, FN, FP, TN으로 계산되는 성능 지표 중에 대표적으로 쓰이는 성능지표 입니다.\n",
        "- TP(True Positive) : 맞는것을 잘 예측\n",
        "- FN(False Negative) : 맞는것을 아니라고 잘못 예측\n",
        "- FP(False Positive) : 아닌것을 맞다고 잘못 예측\n",
        "- TN(True Negative) : 아닌것을 잘 예측  \n",
        "\n",
        "Precision은 TP / (TP+FP)로 FP의 영향을 많이받는 정밀도 Recall은 TP / (TP+FN)으로 FN의 영향을 많이받는 재현율입니다.  \n",
        "그러니까 Precision은 아닌것을 맞다고 잘못 예측하지 않아야 높게 나오고 Recall은 맞는것을 아니라고 잘못 예측하는 경우가 적어야 높게 나옵니다.  \n",
        "필적을 맞추는 경우에야 맞는데 아니라고 하면 곤란하니 Recall이 높은게 더 중요하다고 생각할 수 있겠지만, 여기서는 크게 중요도가 느껴지지 않는 것 같다.  \n",
        "그렇다면 정밀도와 재현율의 수치를 조합해서 종합적인 성능 평가 지표를 내는 F1 score가 높은 기준으로 모델을 평가해보자.  \n",
        "Random Forest모델과 SVM 모델의 평가가 0.99로 동일하게 정말 좋다고 볼 수 있겠지만 SVM모델의 F1 score의 합이 Random Forest보다 0.3 높다.  \n",
        "손글씨 이미지 학습의 우승자는 SVM이 차지했다!"
      ],
      "metadata": {
        "id": "RtnE34ShI4kE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 프로젝트(2) 와인 분류하기"
      ],
      "metadata": {
        "id": "z8_8uJl2QxrW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이번에는 sklearn의 load_wine()의 데이터로 와인을 종류를 분류해 봅시다."
      ],
      "metadata": {
        "id": "1NfAJkHmRda4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (1) 필요한 모듈 import하기"
      ],
      "metadata": {
        "id": "sG5myIyLRX4o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "Y9f_Zu4vQpqm"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이전에 손글씨를 분류할 때 썼던 모듈을 불러옵니다."
      ],
      "metadata": {
        "id": "jOvk_84jRbqJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(2) 데이터 준비  \n",
        "모듈을 불러왔으면 load_wine 메소드를 통해 데이터를 가져옵니다."
      ],
      "metadata": {
        "id": "_tySn4rjRxLm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wine = load_wine()"
      ],
      "metadata": {
        "id": "4aQgZM0yR32C"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "와인 데이터를 불러왔습니다. 이제 데이터를 살펴봅시다."
      ],
      "metadata": {
        "id": "xBolW198Ry0A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(3) 데이터 이해하기  \n",
        "먼저, 아까 했던대로 데이터의 정보들을 조금 살펴봅시다."
      ],
      "metadata": {
        "id": "GUbYoRcBSTMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(wine.DESCR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rn9_efALStPL",
        "outputId": "571ce966-e931-4d23-e5c8-0404824ca14a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. _wine_dataset:\n",
            "\n",
            "Wine recognition dataset\n",
            "------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 178 (50 in each of three classes)\n",
            "    :Number of Attributes: 13 numeric, predictive attributes and the class\n",
            "    :Attribute Information:\n",
            " \t\t- Alcohol\n",
            " \t\t- Malic acid\n",
            " \t\t- Ash\n",
            "\t\t- Alcalinity of ash  \n",
            " \t\t- Magnesium\n",
            "\t\t- Total phenols\n",
            " \t\t- Flavanoids\n",
            " \t\t- Nonflavanoid phenols\n",
            " \t\t- Proanthocyanins\n",
            "\t\t- Color intensity\n",
            " \t\t- Hue\n",
            " \t\t- OD280/OD315 of diluted wines\n",
            " \t\t- Proline\n",
            "\n",
            "    - class:\n",
            "            - class_0\n",
            "            - class_1\n",
            "            - class_2\n",
            "\t\t\n",
            "    :Summary Statistics:\n",
            "    \n",
            "    ============================= ==== ===== ======= =====\n",
            "                                   Min   Max   Mean     SD\n",
            "    ============================= ==== ===== ======= =====\n",
            "    Alcohol:                      11.0  14.8    13.0   0.8\n",
            "    Malic Acid:                   0.74  5.80    2.34  1.12\n",
            "    Ash:                          1.36  3.23    2.36  0.27\n",
            "    Alcalinity of Ash:            10.6  30.0    19.5   3.3\n",
            "    Magnesium:                    70.0 162.0    99.7  14.3\n",
            "    Total Phenols:                0.98  3.88    2.29  0.63\n",
            "    Flavanoids:                   0.34  5.08    2.03  1.00\n",
            "    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\n",
            "    Proanthocyanins:              0.41  3.58    1.59  0.57\n",
            "    Colour Intensity:              1.3  13.0     5.1   2.3\n",
            "    Hue:                          0.48  1.71    0.96  0.23\n",
            "    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\n",
            "    Proline:                       278  1680     746   315\n",
            "    ============================= ==== ===== ======= =====\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\n",
            "    :Creator: R.A. Fisher\n",
            "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
            "    :Date: July, 1988\n",
            "\n",
            "This is a copy of UCI ML Wine recognition datasets.\n",
            "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
            "\n",
            "The data is the results of a chemical analysis of wines grown in the same\n",
            "region in Italy by three different cultivators. There are thirteen different\n",
            "measurements taken for different constituents found in the three types of\n",
            "wine.\n",
            "\n",
            "Original Owners: \n",
            "\n",
            "Forina, M. et al, PARVUS - \n",
            "An Extendible Package for Data Exploration, Classification and Correlation. \n",
            "Institute of Pharmaceutical and Food Analysis and Technologies,\n",
            "Via Brigata Salerno, 16147 Genoa, Italy.\n",
            "\n",
            "Citation:\n",
            "\n",
            "Lichman, M. (2013). UCI Machine Learning Repository\n",
            "[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\n",
            "School of Information and Computer Science. \n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "  (1) S. Aeberhard, D. Coomans and O. de Vel, \n",
            "  Comparison of Classifiers in High Dimensional Settings, \n",
            "  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \n",
            "  Mathematics and Statistics, James Cook University of North Queensland. \n",
            "  (Also submitted to Technometrics). \n",
            "\n",
            "  The data was used with many others for comparing various \n",
            "  classifiers. The classes are separable, though only RDA \n",
            "  has achieved 100% correct classification. \n",
            "  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \n",
            "  (All results using the leave-one-out technique) \n",
            "\n",
            "  (2) S. Aeberhard, D. Coomans and O. de Vel, \n",
            "  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \n",
            "  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \n",
            "  Mathematics and Statistics, James Cook University of North Queensland. \n",
            "  (Also submitted to Journal of Chemometrics).\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wine.target_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OlKPvI4TDk3",
        "outputId": "cacf49d7-f5b7-4b59-e5e8-56afe683e847"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['class_0', 'class_1', 'class_2'], dtype='<U7')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "와인에 대한 178개의 데이터가 담겨있습니다. 13개의 Feature를 가지고 3가지 클래스로 분류되네요.  \n",
        "와인을 잘 몰라서 각 Feature가 무엇을 뜻하는지 자세히 모르겠기 때문에.. 모든 Feature를 학습시켜 주도록 합시다.  \n",
        "wine 데이터와 정답지를 변수에 담아주도록 하겠습니다.\n"
      ],
      "metadata": {
        "id": "mur95q9pS3yh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wine_data = wine.data\n",
        "label_data = wine.target"
      ],
      "metadata": {
        "id": "rNuDhf7WWOtU"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (4) train, test데이터 분리  \n",
        "모델 학습용 데이터와 테스트 데이터를 분리해 주겠습니다."
      ],
      "metadata": {
        "id": "Om7nWNdOWY3W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(wine_data, label_data, test_size=0.2, random_state=20)"
      ],
      "metadata": {
        "id": "s8iyJKJzWh9H"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (5) 다양한 모델로 학습시켜보기  \n",
        "아까 손글씨 데이터에 적용했던 대로 각 모델에 데이터를 학습시키고 비교할 수 있도록 예측값을 담겠습니다."
      ],
      "metadata": {
        "id": "jPXYVJWsW0M-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision Tree\n",
        "decision_tree = DecisionTreeClassifier(random_state=20)\n",
        "decision_tree.fit(X_train, y_train)\n",
        "y_pred_decision_tree = decision_tree.predict(X_test)\n",
        "\n",
        "#Random Forest\n",
        "random_forest = RandomForestClassifier(random_state=20)\n",
        "random_forest.fit(X_train, y_train)\n",
        "y_pred_random_forest = random_forest.predict(X_test)\n",
        "\n",
        "#SVM\n",
        "svm_model = svm.SVC(random_state=20)\n",
        "svm_model.fit(X_train, y_train)\n",
        "y_pred_svm = svm_model.predict(X_test)\n",
        "\n",
        "#SGD\n",
        "sgd_model = SGDClassifier(random_state=20)\n",
        "sgd_model.fit(X_train, y_train)\n",
        "y_pred_sgd = sgd_model.predict(X_test)\n",
        "\n",
        "#Logistic Regression\n",
        "logistic_model = LogisticRegression(random_state=20)\n",
        "logistic_model.fit(X_train, y_train)\n",
        "y_pred_logistic = sgd_model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zj1zstVvXAk2",
        "outputId": "72d0d81e-f591-4e4c-8589-c749b0be442e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이런.. SVM 모델에서 max_iter 값을 설정해 주지 않아서 또 오류가 발생했네요 max_iter값을 조정하여 다시 학습시켜 주겠습니다."
      ],
      "metadata": {
        "id": "77iD8YilYKJb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svm_model = svm.SVC(random_state=20, max_iter = 300)\n",
        "svm_model.fit(X_train, y_train)\n",
        "y_pred_svm = svm_model.predict(X_test)"
      ],
      "metadata": {
        "id": "qabztNlhYPA6"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (6) 모델을 평가해 보기  \n",
        "이번 모델도 정밀도와 재현율의 중요도가 크게 구분되지는 않는것 같습니다. (제 뇌피셜..)  \n",
        "그러니 이번에도 F1 score를 기준으로 모델을 평가해 보겠습니다."
      ],
      "metadata": {
        "id": "RlzQx5urYT3V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Decision Tree : \\n', classification_report(y_test, y_pred_decision_tree))\n",
        "print('Random Forest : \\n', classification_report(y_test, y_pred_random_forest))\n",
        "print('SVM : \\n', classification_report(y_test, y_pred_svm))\n",
        "print('SGD : \\n', classification_report(y_test, y_pred_sgd))\n",
        "print('Logistic : \\n', classification_report(y_test, y_pred_logistic))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2MXqC5NY5i2",
        "outputId": "671b1f0b-f319-4112-ef16-2f3a51f22e14"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      0.94      0.97        17\n",
            "           2       0.90      1.00      0.95         9\n",
            "\n",
            "    accuracy                           0.97        36\n",
            "   macro avg       0.97      0.98      0.97        36\n",
            "weighted avg       0.98      0.97      0.97        36\n",
            "\n",
            "Random Forest : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      1.00      1.00        17\n",
            "           2       1.00      1.00      1.00         9\n",
            "\n",
            "    accuracy                           1.00        36\n",
            "   macro avg       1.00      1.00      1.00        36\n",
            "weighted avg       1.00      1.00      1.00        36\n",
            "\n",
            "SVM : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       0.71      0.71      0.71        17\n",
            "           2       0.44      0.44      0.44         9\n",
            "\n",
            "    accuracy                           0.72        36\n",
            "   macro avg       0.72      0.72      0.72        36\n",
            "weighted avg       0.72      0.72      0.72        36\n",
            "\n",
            "SGD : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.37      1.00      0.54        10\n",
            "           1       0.89      0.47      0.62        17\n",
            "           2       0.00      0.00      0.00         9\n",
            "\n",
            "    accuracy                           0.50        36\n",
            "   macro avg       0.42      0.49      0.39        36\n",
            "weighted avg       0.52      0.50      0.44        36\n",
            "\n",
            "Logistic : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.37      1.00      0.54        10\n",
            "           1       0.89      0.47      0.62        17\n",
            "           2       0.00      0.00      0.00         9\n",
            "\n",
            "    accuracy                           0.50        36\n",
            "   macro avg       0.42      0.49      0.39        36\n",
            "weighted avg       0.52      0.50      0.44        36\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "오.. 랜덤포레스트 모델이 압도적인 성능을 보이네요. SGD와 Logistic 모델은 random_state를 바꿔가며 돌려보았지만 2클래스는 전혀 구분하지 못하는 모습을 보입니다.  \n",
        "wine 분류 모델의 우승자는 랜덤 포레스트네요!"
      ],
      "metadata": {
        "id": "DxqH6ydkaDDm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (3) 유방암 여부 진단하기  \n",
        "마지막입니다. 유방암 여부를 진단해 보도록 하죠."
      ],
      "metadata": {
        "id": "S7pATpwkbVQL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (1) 필요한 모듈 import하기  \n",
        "마찬가지로 학습과 평가에 관련된 모듈들을 import해줍니다."
      ],
      "metadata": {
        "id": "juhjcBkqbn9K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "qbJn5xAtbuvz"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (2) 데이터 준비   \n",
        "sklearn.datasets의 유방암 관련 데이터를 받아오도록 합시다."
      ],
      "metadata": {
        "id": "QkPH-mWwb0w5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "breast_cancer = load_breast_cancer()"
      ],
      "metadata": {
        "id": "6rELYVUcb-At"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (3) 데이터 이해하기  \n",
        "breast_cancer의 데이터를 한번 확인해 보겠습니다."
      ],
      "metadata": {
        "id": "y6laeswkcCot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(breast_cancer.DESCR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msaQQSctcH_Q",
        "outputId": "49f4a18b-923e-4705-980b-43dd993f0d0b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. _breast_cancer_dataset:\n",
            "\n",
            "Breast cancer wisconsin (diagnostic) dataset\n",
            "--------------------------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 569\n",
            "\n",
            "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
            "\n",
            "    :Attribute Information:\n",
            "        - radius (mean of distances from center to points on the perimeter)\n",
            "        - texture (standard deviation of gray-scale values)\n",
            "        - perimeter\n",
            "        - area\n",
            "        - smoothness (local variation in radius lengths)\n",
            "        - compactness (perimeter^2 / area - 1.0)\n",
            "        - concavity (severity of concave portions of the contour)\n",
            "        - concave points (number of concave portions of the contour)\n",
            "        - symmetry\n",
            "        - fractal dimension (\"coastline approximation\" - 1)\n",
            "\n",
            "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
            "        worst/largest values) of these features were computed for each image,\n",
            "        resulting in 30 features.  For instance, field 0 is Mean Radius, field\n",
            "        10 is Radius SE, field 20 is Worst Radius.\n",
            "\n",
            "        - class:\n",
            "                - WDBC-Malignant\n",
            "                - WDBC-Benign\n",
            "\n",
            "    :Summary Statistics:\n",
            "\n",
            "    ===================================== ====== ======\n",
            "                                           Min    Max\n",
            "    ===================================== ====== ======\n",
            "    radius (mean):                        6.981  28.11\n",
            "    texture (mean):                       9.71   39.28\n",
            "    perimeter (mean):                     43.79  188.5\n",
            "    area (mean):                          143.5  2501.0\n",
            "    smoothness (mean):                    0.053  0.163\n",
            "    compactness (mean):                   0.019  0.345\n",
            "    concavity (mean):                     0.0    0.427\n",
            "    concave points (mean):                0.0    0.201\n",
            "    symmetry (mean):                      0.106  0.304\n",
            "    fractal dimension (mean):             0.05   0.097\n",
            "    radius (standard error):              0.112  2.873\n",
            "    texture (standard error):             0.36   4.885\n",
            "    perimeter (standard error):           0.757  21.98\n",
            "    area (standard error):                6.802  542.2\n",
            "    smoothness (standard error):          0.002  0.031\n",
            "    compactness (standard error):         0.002  0.135\n",
            "    concavity (standard error):           0.0    0.396\n",
            "    concave points (standard error):      0.0    0.053\n",
            "    symmetry (standard error):            0.008  0.079\n",
            "    fractal dimension (standard error):   0.001  0.03\n",
            "    radius (worst):                       7.93   36.04\n",
            "    texture (worst):                      12.02  49.54\n",
            "    perimeter (worst):                    50.41  251.2\n",
            "    area (worst):                         185.2  4254.0\n",
            "    smoothness (worst):                   0.071  0.223\n",
            "    compactness (worst):                  0.027  1.058\n",
            "    concavity (worst):                    0.0    1.252\n",
            "    concave points (worst):               0.0    0.291\n",
            "    symmetry (worst):                     0.156  0.664\n",
            "    fractal dimension (worst):            0.055  0.208\n",
            "    ===================================== ====== ======\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "\n",
            "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
            "\n",
            "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
            "\n",
            "    :Donor: Nick Street\n",
            "\n",
            "    :Date: November, 1995\n",
            "\n",
            "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
            "https://goo.gl/U2Uwz2\n",
            "\n",
            "Features are computed from a digitized image of a fine needle\n",
            "aspirate (FNA) of a breast mass.  They describe\n",
            "characteristics of the cell nuclei present in the image.\n",
            "\n",
            "Separating plane described above was obtained using\n",
            "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
            "Construction Via Linear Programming.\" Proceedings of the 4th\n",
            "Midwest Artificial Intelligence and Cognitive Science Society,\n",
            "pp. 97-101, 1992], a classification method which uses linear\n",
            "programming to construct a decision tree.  Relevant features\n",
            "were selected using an exhaustive search in the space of 1-4\n",
            "features and 1-3 separating planes.\n",
            "\n",
            "The actual linear program used to obtain the separating plane\n",
            "in the 3-dimensional space is that described in:\n",
            "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
            "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
            "Optimization Methods and Software 1, 1992, 23-34].\n",
            "\n",
            "This database is also available through the UW CS ftp server:\n",
            "\n",
            "ftp ftp.cs.wisc.edu\n",
            "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
            "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
            "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
            "     San Jose, CA, 1993.\n",
            "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
            "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
            "     July-August 1995.\n",
            "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
            "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
            "     163-171.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breast_cancer.target_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3EyvIQucmVq",
        "outputId": "d277e238-de8f-4b52-a764-b55aef10ba20"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['malignant', 'benign'], dtype='<U9')"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "30가지의 feature를 가지는 569개의 데이터를 가지고 있네요.  \n",
        "클래스는 양성과 음성 두가지로 구분되는 듯 합니다. 학습을 위해 데이터를 변수에 담아보겠습니다.  \n",
        "이번엔 변수가 너무 길어질 것 같으니 훈련용 데이터라는 의미로 train_data 변수를 사용하겠습니다."
      ],
      "metadata": {
        "id": "4bomvxPWc4o3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = breast_cancer.data\n",
        "label_data = breast_cancer.target"
      ],
      "metadata": {
        "id": "Kq4P9s0PdJr_"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (4) train, test 데이터 분리  \n",
        "이제 학습용 데이터와 테스트용 데이터로 다시 분리해 주겠습니다."
      ],
      "metadata": {
        "id": "yeXCUw9bdk_g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(train_data, label_data, test_size=0.2, random_state=20)"
      ],
      "metadata": {
        "id": "-D3_493zdwcF"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(5) 다양한 모델로 학습시켜보기  \n",
        "분류된 데이터를 각 모델에 적용해보겠습니다. 이번엔 SVM 모델에 max_iter까지 넉넉하게 적용하여 오류가 안나도록 해보겠습니다."
      ],
      "metadata": {
        "id": "zpQrbc-Fd7FL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision Tree\n",
        "decision_tree = DecisionTreeClassifier(random_state=20)\n",
        "decision_tree.fit(X_train, y_train)\n",
        "y_pred_decision_tree = decision_tree.predict(X_test)\n",
        "\n",
        "#Random Forest\n",
        "random_forest = RandomForestClassifier(random_state=20)\n",
        "random_forest.fit(X_train, y_train)\n",
        "y_pred_random_forest = random_forest.predict(X_test)\n",
        "\n",
        "#SVM\n",
        "svm_model = svm.SVC(random_state=20, max_iter=1000)\n",
        "svm_model.fit(X_train, y_train)\n",
        "y_pred_svm = svm_model.predict(X_test)\n",
        "\n",
        "#SGD\n",
        "sgd_model = SGDClassifier(random_state=20)\n",
        "sgd_model.fit(X_train, y_train)\n",
        "y_pred_sgd = sgd_model.predict(X_test)\n",
        "\n",
        "#Logistic Regression\n",
        "logistic_model = LogisticRegression(random_state=20)\n",
        "logistic_model.fit(X_train, y_train)\n",
        "y_pred_logistic = sgd_model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYuLebxPeHXY",
        "outputId": "fbe8681b-d7c6-4cce-b589-65a12a9ab722"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ".... SVM에 max_iter를 적용해 줬더니 이번엔 Logistic 모델에서 max_iter 관련 오류가 발생하네요.. 값을 조정해 다시 학습을 진행해 줍니다."
      ],
      "metadata": {
        "id": "3N3JMIsseyRs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Logistic Regression\n",
        "logistic_model = LogisticRegression(random_state=20, max_iter=2000)\n",
        "logistic_model.fit(X_train, y_train)\n",
        "y_pred_logistic = sgd_model.predict(X_test)"
      ],
      "metadata": {
        "id": "A3eQdmDDfPdk"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (6) 모델을 평가해 보기\n",
        "다시 모델을 평가해봅시다."
      ],
      "metadata": {
        "id": "W3OPKc-VfRfN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Decision Tree : \\n', classification_report(y_test, y_pred_decision_tree))\n",
        "print('Random Forest : \\n', classification_report(y_test, y_pred_random_forest))\n",
        "print('SVM : \\n', classification_report(y_test, y_pred_svm))\n",
        "print('SGD : \\n', classification_report(y_test, y_pred_sgd))\n",
        "print('Logistic : \\n', classification_report(y_test, y_pred_logistic))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qKedATPfYP8",
        "outputId": "3cd86af9-cb2c-4390-e6e8-df90e8d49e16"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.92      0.94        48\n",
            "           1       0.94      0.97      0.96        66\n",
            "\n",
            "    accuracy                           0.95       114\n",
            "   macro avg       0.95      0.94      0.95       114\n",
            "weighted avg       0.95      0.95      0.95       114\n",
            "\n",
            "Random Forest : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98        48\n",
            "           1       0.97      1.00      0.99        66\n",
            "\n",
            "    accuracy                           0.98       114\n",
            "   macro avg       0.99      0.98      0.98       114\n",
            "weighted avg       0.98      0.98      0.98       114\n",
            "\n",
            "SVM : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.83      0.91        48\n",
            "           1       0.89      1.00      0.94        66\n",
            "\n",
            "    accuracy                           0.93       114\n",
            "   macro avg       0.95      0.92      0.93       114\n",
            "weighted avg       0.94      0.93      0.93       114\n",
            "\n",
            "SGD : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.85      0.90        48\n",
            "           1       0.90      0.97      0.93        66\n",
            "\n",
            "    accuracy                           0.92       114\n",
            "   macro avg       0.93      0.91      0.92       114\n",
            "weighted avg       0.92      0.92      0.92       114\n",
            "\n",
            "Logistic : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.85      0.90        48\n",
            "           1       0.90      0.97      0.93        66\n",
            "\n",
            "    accuracy                           0.92       114\n",
            "   macro avg       0.93      0.91      0.92       114\n",
            "weighted avg       0.92      0.92      0.92       114\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "여태까지는 정밀도와 재현율이 크게 상관없어 두 지표를 모두 계산하는 F1 score로 모델을 평가했지만 암을 진단하는 경우에는 얘기가 조금 달라집니다.  \n",
        "만약 양성 환자인데 음성이라고 판단해버려서 병을 놓치게 되면 큰일이니까요. 그런 면에서 FN(False Negative)의 영향이 크게 작용하는 Recall 지표가 큰 값이 더 좋은 모델이라고 생각할 수 있습니다.  \n",
        "그런데 굳이 recall을 보지 않더라도 랜덤포레스트의 평가수치가 다른 모델에 비해 더 좋아보이네요.  \n",
        "이번에도 랜덤포레스트 모델이 우승입니다."
      ],
      "metadata": {
        "id": "8O3ARrpFfbWd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (4) 회고  \n",
        "이번 Exploration 노드를 진행하면서 여러 데이터를 사용하여 데이터를 확인하는 법과 데이터를 학습시키는 모델에 대해 알아보았다.  \n",
        "캐글 필사에서 그냥 시켜서 랜덤포레스트가 어떤건지 대충 알고 사용했었는데 이번에 다양한 모델을 공부해보고 다양한 데이터에 모델을 적용해 보니 왜 타이타닉 필사에서 랜덤포레스트를 사용했는지 알겠다.  의사결정트리의 단점을 보완해서인지 모두 좋은 평가값이 나오는 것을 확인할 수 있었다.  \n",
        "SGD에 대해서는 조금 더 짚고 넘어가고 싶은데 경사 하강법이라는 개념 자체가 아직 머릿속에 정리가 되지 않아서 조금 더 공부를 해봐야 할 것 같다.  \n",
        "SVM은 손글씨 구분에서는 좋은 성능을 보였지만 나머지 두 데이터에서는 비교적 낮은 성능을 보였는데, 아무래도 학습을 통해 각 클래스에 해당하는 확률 오차를 계속 줄여가는 학습 모델이다 보니 데이터가 더 많을때 유리한 모습을 보인게 아닌가 하는 생각이 들기도 한다.  \n",
        "와인 데이터에서 SGD와 Logistic 모델이 2클래스 데이터를 전혀 분류하지 못해서 random_state를 바꾸어가며 실행해 봤는데 여전히 잘 되지 않아서 train_test_split의 state값도 변경해 봤는데 여전히 0이 나왔다. 다른 조원들이 한거나 인터넷 글들을 찾아보면 SGD에서의 2클래스 분류는 0이지만 Logistic에서는 잘 분류하던데 이상하다.."
      ],
      "metadata": {
        "id": "41NnF7hAgPJK"
      }
    }
  ]
}